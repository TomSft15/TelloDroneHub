# from droneConnection import drone_connection
# from keyControl import key_control
# from signRecognitionModule import mediapipe_gesture_control
# import pygame as py
# import time
# from commands import Commands
# import cv2
# import threading
# import os
# from datetime import datetime
# import mediapipe as mp
# import base64
# import socketio
# import logging
# logging.basicConfig(level=logging.INFO)


# def init_pygame():
#     py.init()
#     py.display.set_caption("Tello Drone Controller")
#     py.display.set_mode((360, 240))

# def capture_camera():
#     cap = cv2.VideoCapture(0)  # 0 pour la camÃ©ra par dÃ©faut

#     if not cap.isOpened():
#         print("Erreur : Impossible d'ouvrir la camÃ©ra")
#         return

#     while True:
#         ret, frame = cap.read()
#         if not ret:
#             print("Erreur : Impossible de lire le frame")
#             break

#         cv2.imshow("Camera", frame)

#         key = cv2.waitKey(1) & 0xFF
#         if key == ord('q'):  # Quitter la vidÃ©o avec 'q'
#             break

#     cap.release()
#     cv2.destroyAllWindows()

# def stream_video_drone(drone):
#     # Connexion au serveur Socket.IO
#     sio = socketio.Client()
#     try:
#         sio.connect('http://localhost:3000')  # Adapter l'URL si nÃ©cessaire
#         print("ConnectÃ© au serveur Socket.IO")
#     except Exception as e:
#         print("Erreur de connexion au serveur Socket.IO :", e)
#         return

#     drone.streamon()  # Active le streaming vidÃ©o
#     if not os.path.exists("pictures"):
#         os.makedirs("pictures")
#     while True:
#         frame = drone.get_frame_read().frame  # Capture l'image actuelle
#         frame = cv2.resize(frame, (640, 480))  # Redimensionne l'image

#         # Affiche la frame en local
#         cv2.imshow("Tello Camera", frame)
        
#         # Encodage de la frame en JPEG
#         ret, buffer = cv2.imencode('.jpg', frame)
#         if ret:
#             # Conversion en base64 pour l'envoi via Socket.IO
#             jpg_as_text = base64.b64encode(buffer).decode('utf-8')
#             sio.emit('video_frame', jpg_as_text)

#         key = cv2.waitKey(1) & 0xFF
#         if key == ord('q'):  # Quitter la vidÃ©o avec 'q'
#             break
#         elif key == ord('n'):  # ğŸ“¸ Prendre une photo avec 'n'
#             timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
#             filename = f"pictures/photo_{timestamp}.jpg"
#             cv2.imwrite(filename, frame)  # Sauvegarde l'image
#             print(f"ğŸ“¸ Photo sauvegardÃ©e : {filename}")

#     drone.streamoff()  # DÃ©sactive le streaming
#     sio.disconnect()
#     cv2.destroyAllWindows()  # Ferme la fenÃªtre vidÃ©o

# def main():
#     drone = drone_connection()  # DÃ©commentez si vous souhaitez connecter le drone
#     init_pygame()
    
#     clock = py.time.Clock()
#     time.sleep(8)
    
#     print("""
# Commandes disponibles :
# - a : DÃ©collage
# - e : Atterrissage
# - z : Avancer
# - s : Reculer
# - q : Aller Ã  gauche
# - d : Aller Ã  droite
# - FlÃ¨che haut : Monter
# - FlÃ¨che bas : Descendre
# - FlÃ¨che gauche : Rotation gauche
# - FlÃ¨che droite : Rotation droite
# - t : Front flip
# - g : Back flip
# - f : Left flip
# - h : Right flip
# - i : Speech recognition
# - p : ArrÃªt d'urgence
# - m : Quitter le programme

# Commandes gestuelles via MediaPipe :
# - Main ouverte (5 doigts Ã©tendus) : takeoff (dÃ©collage)
# - Main fermÃ©e (aucun doigt Ã©tendu) : land (atterrissage)
# - Pouce tendu en haut (avec main fermÃ©e) : monte (monter)
# - Pouce tendu en bas (avec main fermÃ©e) : descend (descendre)
# Appuyez sur 'q' pour quitter la dÃ©tection gestuelle.
# """)
    
#     hand_position = []
#     shared_commands = []
#     last_command_time = time.time()
#     command_delay = 1.0  # DÃ©lai de 1 seconde entre les commandes
    
#     # Lancement de la dÃ©tection gestuelle dans un thread sÃ©parÃ©
#     # gesture_thread = threading.Thread(target=mediapipe_gesture_control, args=(None, hand_position, shared_commands), daemon=True)
#     # gesture_thread.start()
    
#     video_thread = threading.Thread(target=stream_video_drone, args=(drone,))
#     video_thread.start()
    
#     # Si vous souhaitez simplement visualiser le flux de la camÃ©ra sans dÃ©tection, vous pouvez utiliser capture_camera()
#     # capture_camera()
#     # stream_video_drone(drone)
    
#     running = True
#     while running:
#         for event in py.event.get():
#             if event.type == py.QUIT:
#                 print("ğŸš ArrÃªt du programme...")
#                 running = False

#         # Exemple de rÃ©cupÃ©ration des commandes clavier (dÃ©commentez si vous utilisez le contrÃ´le par touches)
#         tabControl = key_control(drone) #commandsClass)
#         drone.send_rc_control(tabControl[0], tabControl[1], tabControl[2], tabControl[3])
        
#         # Utilisation des commandes partagÃ©es
#         current_time = time.time()
#         if shared_commands and (current_time - last_command_time >= command_delay):
#             command = shared_commands.pop(0)
#             print(f"Commande reÃ§ue : {command}")
#             last_command_time = current_time
        
#         py.display.update()
#         clock.tick(30)
    
#     py.quit()
#     print("ğŸ Programme terminÃ©.")
    
# if __name__ == "__main__":
#     main()
from droneConnection import drone_connection
from keyControl import key_control
from signRecognitionModule import mediapipe_gesture_control
import pygame as py
import time
from commands import Commands
import cv2
import threading
import os
from datetime import datetime
import mediapipe as mp
import base64
import socketio
import logging
logging.basicConfig(level=logging.INFO)


def init_pygame():
    py.init()
    py.display.set_caption("Tello Drone Controller")
    py.display.set_mode((360, 240))

def capture_camera():
    cap = cv2.VideoCapture(0)  # 0 pour la camÃ©ra par dÃ©faut

    if not cap.isOpened():
        print("Erreur : Impossible d'ouvrir la camÃ©ra")
        return

    while True:
        ret, frame = cap.read()
        if not ret:
            print("Erreur : Impossible de lire le frame")
            break

        cv2.imshow("Camera", frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):  # Quitter la vidÃ©o avec 'q'
            break

    cap.release()
    cv2.destroyAllWindows()

def stream_video_drone(drone):
    # Connexion au serveur Socket.IO
    sio = socketio.Client()
    try:
        sio.connect('http://localhost:3000')  # Adapter l'URL si nÃ©cessaire
        print("ConnectÃ© au serveur Socket.IO")
    except Exception as e:
        print("Erreur de connexion au serveur Socket.IO :", e)
        return

    drone.streamon()  # Active le streaming vidÃ©o
    if not os.path.exists("pictures"):
        os.makedirs("pictures")
    while True:
        frame = drone.get_frame_read().frame  # Capture l'image actuelle
        frame = cv2.resize(frame, (640, 480))  # Redimensionne l'image

        # Affiche la frame en local
        cv2.imshow("Tello Camera", frame)
        
        # Encodage de la frame en JPEG
        ret, buffer = cv2.imencode('.jpg', frame)
        if ret:
            # Conversion en base64 pour l'envoi via Socket.IO
            jpg_as_text = base64.b64encode(buffer).decode('utf-8')
            sio.emit('video_frame', jpg_as_text)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):  # Quitter la vidÃ©o avec 'q'
            break
        elif key == ord('n'):  # ğŸ“¸ Prendre une photo avec 'n'
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            filename = f"pictures/photo_{timestamp}.jpg"
            cv2.imwrite(filename, frame)  # Sauvegarde l'image
            print(f"ğŸ“¸ Photo sauvegardÃ©e : {filename}")

    drone.streamoff()  # DÃ©sactive le streaming
    sio.disconnect()
    cv2.destroyAllWindows()  # Ferme la fenÃªtre vidÃ©o

def main():
    # drone = drone_connection()  # DÃ©commentez si vous souhaitez connecter le drone
    init_pygame()
    
    clock = py.time.Clock()
    time.sleep(8)
    
    print("""
Commandes disponibles :
- a : DÃ©collage
- e : Atterrissage
- z : Avancer
- s : Reculer
- q : Aller Ã  gauche
- d : Aller Ã  droite
- FlÃ¨che haut : Monter
- FlÃ¨che bas : Descendre
- FlÃ¨che gauche : Rotation gauche
- FlÃ¨che droite : Rotation droite
- t : Front flip
- g : Back flip
- f : Left flip
- h : Right flip
- i : Speech recognition
- p : ArrÃªt d'urgence
- m : Quitter le programme
- g : Activer/dÃ©sactiver la reconnaissance gestuelle

Commandes gestuelles via MediaPipe :
- Main ouverte (5 doigts Ã©tendus) : takeoff (dÃ©collage)
- Main fermÃ©e (aucun doigt Ã©tendu) : land (atterrissage)
- Pouce tendu en haut (avec main fermÃ©e) : monte (monter)
- Pouce tendu en bas (avec main fermÃ©e) : descend (descendre)
- Signe V (index et majeur tendus) : avancer
- Signe OK (pouce et index formant un cercle) : reculer
- Index tendu Ã  gauche : dÃ©placement Ã  gauche
- Index tendu Ã  droite : dÃ©placement Ã  droite
- Index pointÃ© vers le haut : vol stationnaire
- Signe rock (pouce et auriculaire tendus) : looping avant

Appuyez sur 'q' pour quitter la dÃ©tection gestuelle.
""")
    
    hand_position = []
    shared_commands = []
    last_command_time = time.time()
    command_delay = 1.0  # DÃ©lai de 1 seconde entre les commandes
    # commandsClass = Commands(drone)
    
    # Ã‰tat initial de la reconnaissance gestuelle
    gesture_recognition_enabled = False
    gesture_thread = None
    
    # video_thread = threading.Thread(target=stream_video_drone, args=(drone,))
    # video_thread.daemon = True
    # video_thread.start()
    
    capture_camera()
    
    running = True
    while running:
        for event in py.event.get():
            if event.type == py.QUIT:
                print("ğŸš ArrÃªt du programme...")
                running = False

        # Exemple de rÃ©cupÃ©ration des commandes clavier
        # tabControl = key_control(drone, commandsClass)
        # drone.send_rc_control(tabControl[0], tabControl[1], tabControl[2], tabControl[3])
        
        # Activation/dÃ©sactivation de la reconnaissance gestuelle avec la touche g
        keys = py.key.get_pressed()
        if keys[py.K_g]:
            # Utiliser un dÃ©lai pour Ã©viter les activations multiples
            current_time = time.time()
            if current_time - last_command_time >= command_delay:
                gesture_recognition_enabled = not gesture_recognition_enabled
                last_command_time = current_time
                
                if gesture_recognition_enabled:
                    print("ğŸ–ï¸ Reconnaissance gestuelle activÃ©e")
                    # Lancement de la dÃ©tection gestuelle dans un thread sÃ©parÃ©
                    gesture_thread = threading.Thread(
                        target=mediapipe_gesture_control, 
                        args=(drone, hand_position, shared_commands), 
                        daemon=True
                    )
                    gesture_thread.start()
                else:
                    print("âœ‹ Reconnaissance gestuelle dÃ©sactivÃ©e")
                    # Le thread s'arrÃªtera naturellement lors de sa prochaine itÃ©ration
                    gesture_thread = None
        
        # Utilisation des commandes partagÃ©es
        current_time = time.time()
        if shared_commands and (current_time - last_command_time >= command_delay):
            command = shared_commands.pop(0)
            print(f"Commande reÃ§ue : {command}")
            last_command_time = current_time
        
        py.display.update()
        clock.tick(30)
    
    py.quit()
    print("ğŸ Programme terminÃ©.")
    
if __name__ == "__main__":
    main()